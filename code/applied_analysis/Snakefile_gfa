# Snakemake pipeline for analyzing gwas summary statistic data using GFA
#
#
# LICENSE: CC0. Do what you want with the code, but it has no guarantees.
#          https://creativecommons.org/share-your-work/public-domain/cc0/
#
#
# source activate cause_large
#
# ./run_snakemake.sh
#
# don't forget to update cluster.yaml
#
#
#
# Analyses run:
#       For metab and bc analysis, run GFA with:
#           3 different seeds
#           3 estimates of R (ldsc, pt, none)
#           4 variant sets, primary and 3 jittered selection sets
#           Total: 72 GFA runs (36 for each)
#           Don't really need all of these for all R options
#       For main analysis only (R_ldsc, GFA seed 1, primary SNP set):
#           compute GLS loadings and genetic correlation of factors
#           Produce manhattan and qq plots
#           plot factors
#       For comparison analysis with no R (R_none, GFA seed 1, primary SNP set):
#           plot factors
#       For main bc analysis (bc, R_ldsc, GFA seed 1, primary SNP set):
#           compute number of overlapping gw-sig variants for factors and index traits
#           Compute genetic correlation of index traits
#           Plot genetic correlation of factors and of index traits
#           Perform MR with auotimmune traits
#       For R_ldsc analyses:
#           Compare factors across different GFA seeds and SNP sets
#               Can just consider main SNP set with three different seeds 
#               and seed 1 with alternative snp sets. 
#               This is because GFA seed makes almost no impact.


import pandas as pd
import os

from snakemake.utils import validate

localrules: all, check_success, fail, status, final_file, plot_bc, plot_bc_trait, get_mr_results


###### Load configuration file
configfile: "config_gfa.yaml"

# File organization
data_dir = config["out"]["data_dir"] #where the data is
out_dir = config["out"]["output_dir"] #where results will go
os.makedirs(out_dir, exist_ok = True)

prefix_dict = config["input"]

af_min = config["analysis"]["gfa"]["af_thresh"]
sstol_max = config["analysis"]["gfa"]["sample_size_tol"]

include: "common_rules.smk"

                   
## Set up GFA output
gfa_strings = expand("gfaseed{s}_cn{cond_num}",
                     s = config["analysis"]["gfa"]["gfa_seed"], 
                     cond_num = config["analysis"]["R"]["cond_num"])
                     
gfa_files = expand(out_dir + "{prefix}_gfa_{gfas}.ldpruned_{lds}.R_{rs}.final.RDS",
                prefix = prefix_dict.keys(),
                gfas = gfa_strings,
                lds = ld_strings,
                rs = R_strings)

ref_path = config["analysis"]["ldprune"]["ref_path"]

######################################################
plot_dir = "../../results/applied_analysis/plots/"
plot_gfastrings =  "gfaseed1_cn100"
plot_rstring_all = ["ldsc", "none", "pt0.05"]
plot_rstring_main = ["ldsc"]
plot_ldstrings = [x for x in ld_strings if "jitter0_0" in x]

rgcor_files = expand(out_dir + "{prefix}_gls_loadings.{gfas}.ldpruned_{lds}.R_{rs}.Rgcor.RDS",
                prefix = prefix_dict.keys(),
                gfas = plot_gfastrings,
                lds = plot_ldstrings,
                rs = plot_rstring_main)

factor_plots = expand(plot_dir + "{prefix}_plot.{gfas}.ldpruned_{lds}.R_{rs}.png",
                prefix = prefix_dict.keys(),
                gfas = plot_gfastrings,
                lds = plot_ldstrings,
                rs = plot_rstring_all)

qq_plots = expand(plot_dir + "{prefix}_qqplot.{gfas}.ldpruned_{lds}.R_{rs}.1.png",
                prefix = prefix_dict.keys(),
                gfas = plot_gfastrings,
                lds = plot_ldstrings,
                rs = plot_rstring_main)
            
mht_plots = expand(plot_dir + "{prefix}_mhtplot.{gfas}.ldpruned_{lds}.R_{rs}.1.png",
                prefix = prefix_dict.keys(),
                gfas = plot_gfastrings,
                lds = plot_ldstrings,
                rs = plot_rstring_main)




outcome_info_file = "orig_autoimmune.csv"
outcomes = pd.read_csv(outcome_info_file, na_filter=False)['name']
mr_out_dir = "../../results/applied_analysis/mr_results/"
mr_output = expand(plot_dir + "bc_mr_results.{gfas}.ldpruned_{lds}.R_{rs}.csv", 
                   gfas = plot_gfastrings, 
                   lds = plot_ldstrings,
                   rs = plot_rstring_main) 

compgfa_output = expand(plot_dir + "{prefix}_compfits.cn100.ldpruned_r20.01_kb1000_pvalue.R_ldsc.RDS", 
                        prefix = ["bc", "metab"])
#############################################

rule all:
    input: factor_plots,
           rgcor_files,
           qq_plots, mht_plots,
           mr_output,
           plot_dir + "bc_traitgencor_plot.png",
           compgfa_output

# Run GFA
def R_input(wcs):
    global data_dir
    if wcs.Rstring.startswith("pt"):
        return f'{data_dir}{wcs.prefix}_R_estimate.ldpruned_{wcs.ldstring}.R_{wcs.Rstring}.RDS'
    else:
        return f'{data_dir}{wcs.prefix}_R_estimate.R_{wcs.Rstring}.RDS'


rule run_gfa:
    input: Z = expand(data_dir + "{{prefix}}_zmat.ldpruned_{{ldstring}}.{chrom}.RDS", chrom = range(1, 23)),
           R = R_input,
           gwas_info = info_input
    output:  out = out_dir + "{prefix}_gfa_gfaseed{fs}_cn{cond_num}.ldpruned_{ldstring}.R_{Rstring}.1.RDS",
    params: params_file = config["analysis"]["gfa"]["gfa_params"],
            max_snps = config["analysis"]["gfa"]["max_snps"]
    wildcard_constraints: fs = r"\d+"
    script: 'R/4_run_gfa.R'

# This step refits if convergence was not reached
def refit_input(wcs):
    n = int(wcs.n)
    oldn = str(n-1)
    return f'{out_dir}{wcs.prefix}_gfa_gfaseed{wcs.fs}.ldpruned_{wcs.ldstring}.R_{wcs.Rstring}.{oldn}.RDS'

rule refit_gfa:
    input:  inp = refit_input
    output: out = out_dir + "{prefix}_gfa_gfaseed{fs}.ldpruned_{ldstring}.R_{Rstring}.{n}.RDS",
    params: params_file = config["analysis"]["gfa"]["gfa_params"]
    wildcard_constraints: n = r"\d+"
    script: 'R/6_refit_gfa.R'

# Below is snakemake machinery for checking convergence and re-running if necessary

max_gfa_tries =  int(config["analysis"]["gfa"]["maxrep"])

def next_input(wcs):
    global max_gfa_tries
    global out_dir

    check_prefix = f'{wcs.prefix}_check_gfaseed{wcs.fs}.ldpruned_{wcs.ldstring}.R_{wcs.Rstring}.'
    check_files = [y for y in os.listdir(out_dir) if y.startswith(check_prefix) ]
    n_tries = len(check_files) + 1

    success_file = f'{out_dir}{wcs.prefix}_success_gfaseed{wcs.fs}.ldpruned_{wcs.ldstring}.R_{wcs.Rstring}.txt'
    fail_file = f'{out_dir}{wcs.prefix}_fail_gfaseed{wcs.fs}.ldpruned_{wcs.ldstring}.R_{wcs.Rstring}.txt'
    if os.path.exists(success_file):
      print(success_file)
      return success_file
    elif n_tries > max_gfa_tries:
      print(fail_file)
      return fail_file
    else:
      print("back to checkpoint")
      checkpoints.check_success.get(n=n_tries, **wcs)

def final_rds(wcs):
    global out_dir

    check_prefix = f'{wcs.prefix}_check_{wcs.analysis}'
    check_files = [y for y in os.listdir(out_dir) if y.startswith(check_prefix) ]
    n_tries = len(check_files)
    final_gfa_file = f'{out_dir}{wcs.prefix}_gfa_{wcs.analysis}.{n_tries}.RDS'
    return final_gfa_file

checkpoint check_success:
    input: out_dir + "{prefix}_gfa_gfaseed{fs}.ldpruned_{ldstring}.R_{Rstring}.{n}.RDS"
    output: out_check = out_dir + "{prefix}_check_gfaseed{fs}.ldpruned_{ldstring}.R_{Rstring}.{n}.txt"
    params: success_file = out_dir + '{prefix}_success_gfaseed{fs}.ldpruned_{ldstring}.R_{Rstring}.txt'
    wildcard_constraints: n = r"\d+"
    script: "R/5_check_gfa.R"

rule fail:
    output: out_dir + '{prefix}_fail_gfaseed{fs}.ldpruned_{ldstring}.R_{Rstring}.txt'
    wildcard_constraints:  n = r"\d+"
    params: max_tries = max_gfa_tries
    shell: "echo  Model not converged after {params.max_tries} rounds of {maxiter} iterations. > {output} "

rule status:
    input:  next_input
    output: out = out_dir + "{prefix}_status_gfaseed{fs}.ldpruned_{ldstring}.R_{Rstring}.txt",
    shell: "cp {input} {output.out}"

rule final_file:
    input: status_file = out_dir + "{prefix}_status_{analysis}.txt",
    output: out_rds = out_dir + "{prefix}_gfa_{analysis}.final.RDS"
    params: rds = final_rds
    shell: "mv {params.rds} {output.out_rds}"

rule gls_loadings_chrom:
    input: z_file = data_dir + "{prefix}_zmat.{chrom}.RDS",
           gfa_file = out_dir + "{prefix}_gfa_gfaseed{fs}.ldpruned_{ldstring}.R_{Rstring}.final.RDS",
           R = R_input
    output: out = out_dir + "{prefix}_gls_loadings.gfaseed{fs}.ldpruned_{ldstring}.R_{Rstring}.{chrom}.RDS"
    wildcard_constraints: chrom = r"\d+"
    script: "R/7_estL_gls.R"


rule R_ldsc_gls:
    input: Z = expand(out_dir + "{{prefix}}_gls_loadings.{{analysis}}.{chrom}.RDS", chrom = range(1, 23)),
           m = expand(l2_dir + "{chrom}.l2.M_5_50", chrom = range(1, 23)),
           l2 = expand(l2_dir + "{chrom}.l2.ldscore.gz", chrom = range(1, 23))
    output: out = out_dir + "{prefix}_gls_loadings.{analysis}.Rgcor.RDS"
    script: "R/8_estL_gencor.R"




##### MR

def get_outcome_file(wcs):
    global outcome_info_file
    out_ss = pd.read_csv(outcome_info_file)
    return out_ss[out_ss['name'] == wcs.outcome]['raw_data_path'].iloc[0]

rule mr_factor: 
    input: Z = expand(out_dir + "{{prefix}}_gls_loadings.{{analysis}}.{chrom}.RDS", chrom = range(1, 23)),
           outcome_file = get_outcome_file,
           R = out_dir + "{prefix}_gls_loadings.{analysis}.Rgcor.RDS"
    output: out =  mr_out_dir + "{prefix}_mr_fct.{outcome}.{analysis}.RDS"
    wildcard_constraints: 
            outcome = "(" + "|".join(outcomes)+")"
    params: ref_path = ref_path,
            pthresh = 5e-8,
            r2_thresh = 0.01,
            clump_kb = 1000,
            outcome_info_file = outcome_info_file
    resources: mem_mb = 10000
    script: "R/10_mr_factor.R"

rule mr_trait: 
    input: Z = expand(data_dir + "{{prefix}}_zmat.{chrom}.RDS", chrom = range(1, 23)), 
           outcome_file = get_outcome_file,
           R = data_dir + "{prefix}_R_estimate.{rstring}.RDS"
    output: out =  mr_out_dir + "{prefix}_mr_trait.{outcome}.{rstring}.RDS"
    wildcard_constraints: 
            outcome = "(" + "|".join(outcomes)+")"
    params: ref_path = ref_path,
            pthresh = 5e-8,
            r2_thresh = 0.01,
            clump_kb = 1000,
            outcome_info_file = outcome_info_file
    script: "R/10_mr_traits.R"

#####################################3
#
#          Plotting
#
##################################
#
#
#Select top snps for traits and factors after LD pruning (only used for blood cell)
rule topsnps_traits:
    input: Z = data_dir + "{prefix}_zmat.{chrom}.RDS"
    output: out = data_dir + "{prefix}_trait.top_snps.{chrom}.RDS"
    params: ref_path = ref_path, 
            r2_thresh = 0.01, 
            clump_kb = 1000,
            pthresh = "5e-8" 
    wildcard_constraints: chrom = r"\d+"
    script: "R/9_topsnps.R"

rule topsnps_fctgls:
    input: Z = out_dir + "{prefix}_gls_loadings.{analysis}.{chrom}.RDS"
    output: out = out_dir + "{prefix}_gls_loadings.{analysis}.top_snps.{chrom}.RDS"
    params: ref_path = ref_path,
            r2_thresh = 0.01, 
            clump_kb = 1000,
            pthresh = "5e-8" 
    wildcard_constraints: chrom = r"\d+"
    script: "R/9_topsnps.R"


## plot metablic analysis factors
## also computes credibleintervals for pve
rule plot_metab:
    input: gfa_fit = out_dir + "metab_gfa_{analysis}.final.RDS"
    output: out = plot_dir + "metab_plot.{analysis}.png", 
            pve_ci = plot_dir + "metab_pveci_{analysis}.RDS"
    params: nsamp = 1000, level = 0.05
    resources: mem_mb = 20000
    script: "R/12_plot_metab.R"


## blot blood cell trait genetic correlation and trait top snp overlap
rule plot_bc_trait:
    input: trait_gencor = data_dir + "bc_R_estimate.R_ldsc.RDS",
           trait_ld_pruned_files = expand(data_dir + "bc_trait.top_snps.{chrom}.RDS", chrom = range(1, 23)),
    output: trait_gencor_plot = plot_dir + "bc_traitgencor_plot.png",
            trait_overlap_plot = plot_dir + "bc_traitoverlap_plot.png"
    script: "R/12_plot_bloodcell_trait.R"


## blot blood cell analysis factors, blood cell top snp overlap, and blood cell factor genetic correlation
rule plot_bc:
    input: gfa_fit = out_dir + "bc_gfa_{analysis}.final.RDS",
           fct_gencor =  out_dir + "bc_gls_loadings.{analysis}.Rgcor.RDS",
           factor_ld_pruned_files = expand(out_dir + "bc_gls_loadings.{{analysis}}.top_snps.{chrom}.RDS", chrom = range(1, 23))
    output: factor_plot = plot_dir + "bc_plot.{analysis}.png",
    params: fct_gencor_plot = plot_dir + "bc_fctgencor_plot.{analysis}.png",
            factor_overlap_plot = plot_dir + "bc_fctoverlap_plot.{analysis}.png"
    script: "R/12_plot_bloodcell.R"

# QQ plots for factors
rule qq:
    input: Z = expand(out_dir + "{{prefix}}_gls_loadings.{{analysis}}.{chrom}.RDS", chrom = range(1, 23))
    output: qq_out = plot_dir + "{prefix}_qqplot.{analysis}.1.png"
    resources: mem_mb = 20000
    script: "R/12_plot_qqplot.R"

rule mht:
    input: Z_factors = expand(out_dir + "{{prefix}}_gls_loadings.{{analysis}}.{chrom}.RDS", chrom = range(1, 23)),
           Z_traits = expand(data_dir + "{{prefix}}_zmat.{chrom}.RDS", chrom = range(1, 23)), 
           gfa_res =  out_dir + "{prefix}_gfa_{analysis}.final.RDS",
    output: mht_out = plot_dir + "{prefix}_mhtplot.{analysis}.1.png"
    resources: mem_mb = 40000
    script: "R/12_plot_mht.R"

## write table of MR results
rule get_mr_results:
    input: mr_input_factors = expand(mr_out_dir + "bc_mr_fct.{outcome}.{{analysis}}.{{rstring}}.RDS", outcome = outcomes),
           mr_input_traits =  expand(mr_out_dir + "bc_mr_trait.{outcome}.{{rstring}}.RDS", outcome = outcomes),
           gfa_fit = out_dir + "bc_gfa_{analysis}.{rstring}.final.RDS"
    output: out =  plot_dir + "bc_mr_results.{analysis}.{rstring}.csv"
    script: "R/11_get_mr_results.R"

rule compare_gfa:
    input:  expand(out_dir + "{{prefix}}_gfa_gfaseed{s}_cn100.ldpruned_r20.01_kb1000_pvalue_jitter{j}.R_ldsc.final.RDS", s = [1, 2, 3], j = ["0_0", "0.5_1", "0.5_2", "0.5_3"])
    output: out = plot_dir + "{prefix}_compfits.cn100.ldpruned_r20.01_kb1000_pvalue.R_ldsc.RDS"
    resources: mem_mb = 10000
    script: "R/13_compgfa.R"

